{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_community in c:\\users\\user\\anaconda3\\lib\\site-packages (0.3.7)\n",
      "Requirement already satisfied: langchain in c:\\users\\user\\anaconda3\\lib\\site-packages (0.3.7)\n",
      "Requirement already satisfied: langchain_cohere in c:\\users\\user\\anaconda3\\lib\\site-packages (0.3.0)\n",
      "Requirement already satisfied: langchain_groq in c:\\users\\user\\anaconda3\\lib\\site-packages (0.2.1)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain_community) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<2.0.36,>=1.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain_community) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain_community) (3.9.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain_community) (0.5.14)\n",
      "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain_community) (0.4.0)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain_community) (0.3.19)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain_community) (0.1.134)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain_community) (1.26.4)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain_community) (2.5.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain_community) (9.0.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain) (0.3.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain) (2.9.2)\n",
      "Requirement already satisfied: cohere<6.0,>=5.5.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain_cohere) (5.11.0)\n",
      "Requirement already satisfied: langchain-experimental>=0.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain_cohere) (0.3.3)\n",
      "Requirement already satisfied: pandas>=1.4.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain_cohere) (2.2.3)\n",
      "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain_cohere) (0.9.0)\n",
      "Requirement already satisfied: groq<1,>=0.4.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain_groq) (0.11.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.3)\n",
      "Requirement already satisfied: boto3<2.0.0,>=1.34.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from cohere<6.0,>=5.5.6->langchain_cohere) (1.35.38)\n",
      "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from cohere<6.0,>=5.5.6->langchain_cohere) (1.9.7)\n",
      "Requirement already satisfied: httpx>=0.21.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from cohere<6.0,>=5.5.6->langchain_cohere) (0.27.2)\n",
      "Requirement already satisfied: parameterized<0.10.0,>=0.9.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from cohere<6.0,>=5.5.6->langchain_cohere) (0.9.0)\n",
      "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from cohere<6.0,>=5.5.6->langchain_cohere) (2.23.4)\n",
      "Requirement already satisfied: sagemaker<3.0.0,>=2.232.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from cohere<6.0,>=5.5.6->langchain_cohere) (2.232.2)\n",
      "Requirement already satisfied: tokenizers<1,>=0.15 in c:\\users\\user\\anaconda3\\lib\\site-packages (from cohere<6.0,>=5.5.6->langchain_cohere) (0.20.3)\n",
      "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from cohere<6.0,>=5.5.6->langchain_cohere) (2.32.0.20240914)\n",
      "Requirement already satisfied: typing_extensions>=4.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from cohere<6.0,>=5.5.6->langchain_cohere) (4.12.2)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.22.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (4.6.2.post1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (1.8.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\user\\anaconda3\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (1.3.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.17->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.17->langchain_community) (24.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (3.10.11)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas>=1.4.3->langchain_cohere) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas>=1.4.3->langchain_cohere) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas>=1.4.3->langchain_cohere) (2023.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain_community) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain_community) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from SQLAlchemy<2.0.36,>=1.4->langchain_community) (3.0.1)\n",
      "Requirement already satisfied: botocore<1.36.0,>=1.35.38 in c:\\users\\user\\anaconda3\\lib\\site-packages (from boto3<2.0.0,>=1.34.0->cohere<6.0,>=5.5.6->langchain_cohere) (1.35.38)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from boto3<2.0.0,>=1.34.0->cohere<6.0,>=5.5.6->langchain_cohere) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from boto3<2.0.0,>=1.34.0->cohere<6.0,>=5.5.6->langchain_cohere) (0.10.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\user\\anaconda3\\lib\\site-packages (from httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain_cohere) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\user\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.21.2->cohere<6.0,>=5.5.6->langchain_cohere) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.17->langchain_community) (2.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.4.3->langchain_cohere) (1.16.0)\n",
      "Requirement already satisfied: cloudpickle==2.2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (2.2.1)\n",
      "Requirement already satisfied: docker in c:\\users\\user\\anaconda3\\lib\\site-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (7.1.0)\n",
      "Requirement already satisfied: google-pasta in c:\\users\\user\\anaconda3\\lib\\site-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (0.2.0)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (6.11.0)\n",
      "Requirement already satisfied: jsonschema in c:\\users\\user\\anaconda3\\lib\\site-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (4.19.2)\n",
      "Requirement already satisfied: pathos in c:\\users\\user\\anaconda3\\lib\\site-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (0.3.3)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\user\\anaconda3\\lib\\site-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (4.3.6)\n",
      "Requirement already satisfied: protobuf<5.0,>=3.12 in c:\\users\\user\\anaconda3\\lib\\site-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (4.25.5)\n",
      "Requirement already satisfied: psutil in c:\\users\\user\\anaconda3\\lib\\site-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (5.9.0)\n",
      "Requirement already satisfied: sagemaker-core<2.0.0,>=1.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (1.0.10)\n",
      "Requirement already satisfied: sagemaker-mlflow in c:\\users\\user\\anaconda3\\lib\\site-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (0.1.0)\n",
      "Requirement already satisfied: schema in c:\\users\\user\\anaconda3\\lib\\site-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (0.7.7)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (1.0.1)\n",
      "Requirement already satisfied: tblib<4,>=1.7.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (1.7.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\anaconda3\\lib\\site-packages (from sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (4.67.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tokenizers<1,>=0.15->cohere<6.0,>=5.5.6->langchain_cohere) (0.26.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere<6.0,>=5.5.6->langchain_cohere) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere<6.0,>=5.5.6->langchain_cohere) (2024.10.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (3.21.0)\n",
      "Requirement already satisfied: rich<14.0.0,>=13.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from sagemaker-core<2.0.0,>=1.0.0->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (13.9.4)\n",
      "Requirement already satisfied: mock<5.0,>4.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from sagemaker-core<2.0.0,>=1.0.0->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (4.0.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jsonschema->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jsonschema->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jsonschema->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (0.10.6)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from tqdm->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (0.4.6)\n",
      "Requirement already satisfied: pywin32>=304 in c:\\users\\user\\anaconda3\\lib\\site-packages (from docker->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (305.1)\n",
      "Requirement already satisfied: ppft>=1.7.6.9 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pathos->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (1.7.6.9)\n",
      "Requirement already satisfied: dill>=0.3.9 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pathos->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (0.3.9)\n",
      "Requirement already satisfied: pox>=0.3.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pathos->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (0.3.5)\n",
      "Requirement already satisfied: multiprocess>=0.70.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pathos->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (0.70.17)\n",
      "Requirement already satisfied: mlflow>=2.8 in c:\\users\\user\\anaconda3\\lib\\site-packages (from sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (2.16.2)\n",
      "Requirement already satisfied: mlflow-skinny==2.16.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (2.16.2)\n",
      "Requirement already satisfied: Flask<4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (2.3.2)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (1.13.3)\n",
      "Requirement already satisfied: graphene<4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (3.3)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (3.4.1)\n",
      "Requirement already satisfied: matplotlib<4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (3.8.0)\n",
      "Requirement already satisfied: pyarrow<18,>=4.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (14.0.2)\n",
      "Requirement already satisfied: scikit-learn<2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (1.5.2)\n",
      "Requirement already satisfied: scipy<2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (1.13.1)\n",
      "Requirement already satisfied: Jinja2<4,>=3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (3.1.3)\n",
      "Requirement already satisfied: waitress<4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (3.0.0)\n",
      "Requirement already satisfied: cachetools<6,>=5.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (5.5.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (8.1.7)\n",
      "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (0.34.0)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in c:\\users\\user\\anaconda3\\lib\\site-packages (from mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (3.1.37)\n",
      "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (1.28.1)\n",
      "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (1.28.1)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (0.5.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.0->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.0->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (2.18.0)\n",
      "Requirement already satisfied: Mako in c:\\users\\user\\anaconda3\\lib\\site-packages (from alembic!=1.10.0,<2->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (1.3.5)\n",
      "Requirement already satisfied: Werkzeug>=2.3.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from Flask<4->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (3.1.1)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from Flask<4->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (2.2.0)\n",
      "Requirement already satisfied: blinker>=1.6.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from Flask<4->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (1.6.2)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from graphene<4->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (3.2.4)\n",
      "Requirement already satisfied: graphql-relay<3.3,>=3.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from graphene<4->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (3.2.0)\n",
      "Requirement already satisfied: aniso8601<10,>=8 in c:\\users\\user\\anaconda3\\lib\\site-packages (from graphene<4->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (9.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from Jinja2<4,>=3.0->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (2.1.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.0->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (0.1.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib<4->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib<4->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib<4->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib<4->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib<4->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib<4->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (3.0.9)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn<2->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn<2->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (3.5.0)\n",
      "Requirement already satisfied: google-auth~=2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (2.36.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (4.0.7)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (1.2.15)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.49b1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (0.49b1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\user\\anaconda3\\lib\\site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (1.16.0)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (4.0.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (4.9)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.16.2->mlflow>=2.8->sagemaker-mlflow->sagemaker<3.0.0,>=2.232.1->cohere<6.0,>=5.5.6->langchain_cohere) (0.6.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain_community langchain langchain_cohere langchain_groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: neo4j in c:\\users\\user\\anaconda3\\lib\\site-packages (5.26.0)\n",
      "Requirement already satisfied: pytz in c:\\users\\user\\anaconda3\\lib\\site-packages (from neo4j) (2023.3.post1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yfiles_jupyter_graphs import GraphWidget\n",
    "from neo4j import GraphDatabase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "GROQ_API_KEY='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'\n",
    "os.environ[\"GROQ_API_KEY\"]='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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm= ChatGroq(\n",
    "            model='llama3-8b-8192',\n",
    "            temperature=0.6,\n",
    "            api_key=os.getenv(\"GROQ_API_KEY\")\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import Ollama\n",
    "llm =Ollama(model='llama3.2:3b') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEO4J_URI='neo4j+s://ac661595.databases.neo4j.io'\n",
    "NEO4J_USERNAME='neo4j'\n",
    "NEO4J_PASSWORD='CZpLyBr6A_cxF15QEKbQX6mUxblAPxLEXWva6r3_66c'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"NEO4J_URI\"] = NEO4J_URI\n",
    "os.environ[\"NEO4J_USERNAME\"] = NEO4J_USERNAME\n",
    "os.environ[\"NEO4J_PASSWORD\"] = NEO4J_PASSWORD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_community.vectorstores import Neo4jVector\n",
    "from langchain_community.graphs import Neo4jGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Neo4jGraph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 documents from the folder.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader, Docx2txtLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from typing import List\n",
    "from langchain_core.documents import Document\n",
    "import os\n",
    "\n",
    "def load_documents(folder_path: str) -> List[Document]:\n",
    "    documents = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        if filename.endswith('.pdf'):\n",
    "            loader = PyPDFLoader(file_path)\n",
    "        elif filename.endswith('.docx'):\n",
    "            loader = Docx2txtLoader(file_path)\n",
    "        else:\n",
    "            print(f\"Unsupported file type: {filename}\")\n",
    "            continue\n",
    "        documents.extend(loader.load())\n",
    "    return documents\n",
    "\n",
    "folder_path = r\"C:\\Users\\user\\Desktop\\Alchemist AI Assignment\\data\"\n",
    "documents = load_documents(folder_path)\n",
    "print(f\"Loaded {len(documents)} documents from the folder.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: C:\\ProgramData\\sagemaker\\sagemaker\\config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: C:\\Users\\user\\AppData\\Local\\sagemaker\\sagemaker\\config.yaml\n"
     ]
    }
   ],
   "source": [
    "embeddings_model_name='embed-english-v2.0'\n",
    "COHERE_API_KEY='30lAzH7VO1y9M00rSD5ns4gIIxicqxiMnCn1IycB'\n",
    "import os\n",
    "os.environ['COHERE_API_KEY']=COHERE_API_KEY \n",
    "from langchain_cohere import CohereEmbeddings\n",
    "\n",
    "embeddings = CohereEmbeddings(\n",
    "        model=embeddings_model_name,\n",
    "        cohere_api_key=os.getenv('COHERE_API_KEY')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split the documents into 115 chunks.\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=50,\n",
    "    chunk_overlap=10,\n",
    "    length_function=len\n",
    ")\n",
    "\n",
    "splits = text_splitter.split_documents(documents)\n",
    "print(f\"Split the documents into {len(splits)} chunks.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "llm_transformer = LLMGraphTransformer(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_documents = llm_transformer.convert_to_graph_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[GraphDocument(nodes=[Node(id='Mughal Empire', type='Dynasty', properties={}), Node(id='Babur', type='Person', properties={}), Node(id='Akbar The Great', type='Person', properties={}), Node(id='Shah Jahan', type='Person', properties={}), Node(id='Aurangzeb', type='Person', properties={}), Node(id='Timur', type='Person', properties={}), Node(id='Genghis Khan', type='Person', properties={}), Node(id='Mumtaz Mahal', type='Person', properties={}), Node(id='Bahadur Shah Ii', type='Person', properties={})], relationships=[Relationship(source=Node(id='Babur', type='Person', properties={}), target=Node(id='Mughal Empire', type='Dynasty', properties={}), type='ESTABLISHED', properties={}), Relationship(source=Node(id='Akbar The Great', type='Person', properties={}), target=Node(id='Mughal Empire', type='Dynasty', properties={}), type='RULED', properties={}), Relationship(source=Node(id='Shah Jahan', type='Person', properties={}), target=Node(id='Mughal Empire', type='Dynasty', properties={}), type='RULED', properties={}), Relationship(source=Node(id='Aurangzeb', type='Person', properties={}), target=Node(id='Mughal Empire', type='Dynasty', properties={}), type='RULED', properties={}), Relationship(source=Node(id='Mumtaz Mahal', type='Person', properties={}), target=Node(id='Shah Jahan', type='Person', properties={}), type='WIFE', properties={}), Relationship(source=Node(id='Bahadur Shah Ii', type='Person', properties={}), target=Node(id='Mughal Empire', type='Dynasty', properties={}), type='RULED', properties={})], source=Document(metadata={'source': 'C:\\\\Users\\\\user\\\\Desktop\\\\Alchemist AI Assignment\\\\data\\\\The Mughal Empire.pdf', 'page': 0}, page_content='The Mughal Empire, a prominent and influential dynasty, ruled over the Indian subcontinent from the \\nearly 16th century until the mid-18th century, with remnants lasting until the mid-19th century. The \\nempire was established in 1526 by Babur, a descendant of Timur and Genghis Khan, after his victory at \\nthe Battle of Panipat. This victory marked the beginning of a powerful empire that blended Persian \\nculture with the rich traditions of the Indian subcontinent, resulting in a unique and lasting legacy in art, \\narchitecture, and administration. \\nBabur\\'s grandson, Akbar the Great, is often credited with consolidating and expanding the Mughal \\nEmpire. Ascending the throne at the tender age of 13, Akbar displayed exceptional military prowess and \\nstrategic acumen. His policy of religious tolerance and inclusion, known as Sulh-e-Kul or \"universal \\npeace,\" endeared him to his diverse subjects. Akbar\\'s administration was marked by a centralized system \\nof governance with efficient tax collection and revenue management. He also promoted cultural and \\nintellectual pursuits, leading to a flourishing of the arts. The Mughal court became a hub for poets, \\nartists, and scholars, with Persian serving as the lingua franca. \\nThe architectural achievements of the Mughal Empire are among its most enduring legacies. Akbar\\'s \\ngrandson, Shah Jahan, is renowned for commissioning the Taj Mahal, a stunning white marble \\nmausoleum built in memory of his beloved wife, Mumtaz Mahal. This masterpiece is a testament to the \\nMughal\\'s architectural ingenuity and artistic sensibilities. The empire\\'s architectural style, characterized \\nby large domes, slender minarets, and intricate ornamentation, left a lasting imprint on the Indian \\nlandscape. Other notable structures include the Red Fort in Delhi, Fatehpur Sikri, and the Jama Masjid. \\nEconomically, the Mughal Empire was a powerhouse. It benefited from India\\'s rich agricultural output, \\nespecially in cotton, silk, and spices, which were highly sought after in global markets. The empire \\nmaintained a complex network of trade routes that facilitated commerce with Europe, the Middle East, \\nand Southeast Asia. The revenue from these trade activities funded grand architectural projects and a \\nlavish lifestyle for the nobility, while also supporting public works and infrastructure. \\nHowever, the Mughal Empire was not without its challenges. The later years of Shah Jahan\\'s reign saw \\nincreasing court intrigues and succession conflicts. His son, Aurangzeb, expanded the empire to its \\ngreatest territorial extent but at a significant cost. Aurangzeb\\'s policies of religious intolerance and heavy \\ntaxation alienated many of his subjects, leading to widespread discontent. His military campaigns, \\nthough initially successful, stretched the empire\\'s resources thin and led to administrative inefficiencies. \\nThe decline of the Mughal Empire began in earnest in the early 18th century. Internal strife, coupled \\nwith the rise of regional powers like the Marathas, Sikhs, and Rajputs, eroded Mughal authority. \\nAdditionally, the advent of European colonial powers, particularly the British East India Company, further \\nweakened the empire. The decisive blow came with the Battle of Plassey in 1757, where the British \\ndefeated the forces of the Mughal-aligned Nawab of Bengal, marking the beginning of British dominance \\nin India. \\nBy the mid-19th century, the Mughal Empire was a shadow of its former self, reduced to a symbolic \\npresence with little real power. The last Mughal emperor, Bahadur Shah II, was exiled by the British \\nfollowing the Indian Rebellion of 1857, formally ending the Mughal dynasty. Despite its decline, the \\nlegacy of the Mughal Empire endures in India’s cultural, architectural, and historical landscape, \\nsymbolizing a rich period of synthesis and artistic achievement that continues to inspire admiration \\nworldwide. '))]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.add_graph_documents(\n",
    "    graph_documents,\n",
    "    baseEntityLabel=True,\n",
    "    include_source=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yfiles_jupyter_graphs import GraphWidget\n",
    "from neo4j import GraphDatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Neo4jVector\n",
    "vector_index = Neo4jVector.from_existing_graph(\n",
    "    embeddings,\n",
    "    search_type=\"hybrid\",\n",
    "    node_label=\"Document\",\n",
    "    text_node_properties=[\"text\"],\n",
    "    embedding_node_property=\"embedding\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.query(\"CREATE FULLTEXT INDEX entity IF NOT EXISTS FOR (e:__Entity__) ON EACH [e.id]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3553: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "# Extract entities from text\n",
    "class Entities(BaseModel):\n",
    "    \"\"\"Identifying information about entities.\"\"\"\n",
    "\n",
    "    names: List[str] = Field(\n",
    "        ...,\n",
    "        description=\"All the person, organization, or business entities that \"\n",
    "        \"appear in the text\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts.prompt import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are extracting organization and person entities from the text.\",\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Use the given format to extract information from the following \"\n",
    "            \"input: {question}\",\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_chain = prompt | llm.with_structured_output(Entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities=entity_chain.invoke({\"question\": \"Who was Babur?\"}).names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Babur']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores.neo4j_vector import remove_lucene_chars\n",
    "def generate_full_text_query(input: str) -> str:\n",
    "    full_text_query = \"\"\n",
    "    words = [el for el in remove_lucene_chars(input).split() if el]\n",
    "    for word in words[:-1]:\n",
    "        full_text_query += f\" {word}~2 AND\"\n",
    "    full_text_query += f\" {words[-1]}~2\"\n",
    "    return full_text_query.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fulltext index query\n",
    "def structured_retriever(question: str) -> str:\n",
    "    result = \"\"\n",
    "    entities = entity_chain.invoke({\"question\": question})\n",
    "    for entity in entities.names:\n",
    "        response = graph.query(\n",
    "            \"\"\"CALL db.index.fulltext.queryNodes('entity', $query, {limit:2})\n",
    "            YIELD node,score\n",
    "            CALL {\n",
    "              WITH node\n",
    "              MATCH (node)-[r:!MENTIONS]->(neighbor)\n",
    "              RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\n",
    "              UNION ALL\n",
    "              WITH node\n",
    "              MATCH (node)<-[r:!MENTIONS]-(neighbor)\n",
    "              RETURN neighbor.id + ' - ' + type(r) + ' -> ' +  node.id AS output\n",
    "            }\n",
    "            RETURN output LIMIT 50\n",
    "            \"\"\",\n",
    "            {\"query\": generate_full_text_query(entity)},\n",
    "        )\n",
    "        result += \"\\n\".join([el['output'] for el in response])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (node, node) { ... }} {position: line: 3, column: 13, offset: 104} for query: \"CALL db.index.fulltext.queryNodes('entity', $query, {limit:2})\\n            YIELD node,score\\n            CALL {\\n              WITH node\\n              MATCH (node)-[r:!MENTIONS]->(neighbor)\\n              RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\\n              UNION ALL\\n              WITH node\\n              MATCH (node)<-[r:!MENTIONS]-(neighbor)\\n              RETURN neighbor.id + ' - ' + type(r) + ' -> ' +  node.id AS output\\n            }\\n            RETURN output LIMIT 50\\n            \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mughal Empire - COMMISSIONED -> Taj Mahal\n"
     ]
    }
   ],
   "source": [
    "print(structured_retriever(\"Who built the Taj Mahal?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores.neo4j_vector import remove_lucene_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retriever(question: str):\n",
    "    print(f\"Search query: {question}\")\n",
    "    structured_data = structured_retriever(question)\n",
    "    unstructured_data = [el.page_content for el in vector_index.similarity_search(question)]\n",
    "    final_data = f\"\"\"Structured data:\n",
    "{structured_data}\n",
    "Unstructured data:\n",
    "{\"#Document \". join(unstructured_data)}\n",
    "    \"\"\"\n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "_template = \"\"\"Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question,\n",
    "in its original language.\n",
    "Chat History:\n",
    "{chat_history}\n",
    "Follow Up Input: {question}\n",
    "Standalone question:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONDENSE_QUESTION_PROMPT = PromptTemplate.from_template(_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List, Optional\n",
    "def _format_chat_history(chat_history: List[Tuple[str, str]]) -> List:\n",
    "    buffer = []\n",
    "    for human, ai in chat_history:\n",
    "        buffer.append(HumanMessage(content=human))\n",
    "        buffer.append(AIMessage(content=ai))\n",
    "    return buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import (\n",
    "    RunnableBranch,\n",
    "    RunnableLambda,\n",
    "    RunnableParallel,\n",
    "    RunnablePassthrough,\n",
    ")\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "_search_query = RunnableBranch(\n",
    "    # If input includes chat_history, we condense it with the follow-up question\n",
    "    (\n",
    "        RunnableLambda(lambda x: bool(x.get(\"chat_history\"))).with_config(\n",
    "            run_name=\"HasChatHistoryCheck\"\n",
    "        ),  # Condense follow-up question and chat into a standalone_question\n",
    "        RunnablePassthrough.assign(\n",
    "            chat_history=lambda x: _format_chat_history(x[\"chat_history\"])\n",
    "        )\n",
    "        | CONDENSE_QUESTION_PROMPT\n",
    "        | llm\n",
    "        | StrOutputParser(),\n",
    "    ),\n",
    "    # Else, we have no chat history, so just pass through the question\n",
    "    RunnableLambda(lambda x : x[\"question\"]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Use natural language and be concise.\n",
    "Answer:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    RunnableParallel(\n",
    "        {\n",
    "            \"context\": _search_query | retriever,\n",
    "            \"question\": RunnablePassthrough(),\n",
    "        }\n",
    "    )\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search query: Who was Akbar ?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (node, node) { ... }} {position: line: 3, column: 13, offset: 104} for query: \"CALL db.index.fulltext.queryNodes('entity', $query, {limit:2})\\n            YIELD node,score\\n            CALL {\\n              WITH node\\n              MATCH (node)-[r:!MENTIONS]->(neighbor)\\n              RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\\n              UNION ALL\\n              WITH node\\n              MATCH (node)<-[r:!MENTIONS]-(neighbor)\\n              RETURN neighbor.id + ' - ' + type(r) + ' -> ' +  node.id AS output\\n            }\\n            RETURN output LIMIT 50\\n            \"\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL () { ... }} {position: line: 1, column: 1, offset: 0} for query: \"CALL { CALL db.index.vector.queryNodes($index, $k, $embedding) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score UNION CALL db.index.fulltext.queryNodes($keyword_index, $query, {limit: $k}) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score } WITH node, max(score) AS score ORDER BY score DESC LIMIT $k RETURN reduce(str='', k IN ['text'] | str + '\\\\n' + k + ': ' + coalesce(node[k], '')) AS text, node {.*, `embedding`: Null, id: Null, `text`: Null} AS metadata, score\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Akbar was the ruler of the Mughal Empire.'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"question\": \"Who was Akbar ?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search query: Who was Akbar's father?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (node, node) { ... }} {position: line: 3, column: 13, offset: 104} for query: \"CALL db.index.fulltext.queryNodes('entity', $query, {limit:2})\\n            YIELD node,score\\n            CALL {\\n              WITH node\\n              MATCH (node)-[r:!MENTIONS]->(neighbor)\\n              RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\\n              UNION ALL\\n              WITH node\\n              MATCH (node)<-[r:!MENTIONS]-(neighbor)\\n              RETURN neighbor.id + ' - ' + type(r) + ' -> ' +  node.id AS output\\n            }\\n            RETURN output LIMIT 50\\n            \"\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (node, node) { ... }} {position: line: 3, column: 13, offset: 104} for query: \"CALL db.index.fulltext.queryNodes('entity', $query, {limit:2})\\n            YIELD node,score\\n            CALL {\\n              WITH node\\n              MATCH (node)-[r:!MENTIONS]->(neighbor)\\n              RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\\n              UNION ALL\\n              WITH node\\n              MATCH (node)<-[r:!MENTIONS]-(neighbor)\\n              RETURN neighbor.id + ' - ' + type(r) + ' -> ' +  node.id AS output\\n            }\\n            RETURN output LIMIT 50\\n            \"\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL () { ... }} {position: line: 1, column: 1, offset: 0} for query: \"CALL { CALL db.index.vector.queryNodes($index, $k, $embedding) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score UNION CALL db.index.fulltext.queryNodes($keyword_index, $query, {limit: $k}) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score } WITH node, max(score) AS score ORDER BY score DESC LIMIT $k RETURN reduce(str='', k IN ['text'] | str + '\\\\n' + k + ': ' + coalesce(node[k], '')) AS text, node {.*, `embedding`: Null, id: Null, `text`: Null} AS metadata, score\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Babur.'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\n",
    "    {\n",
    "        \"question\": \"Who was Akbar's father?\",\n",
    "        \n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from yfiles_jupyter_graphs import GraphWidget\n",
    "from neo4j import GraphDatabase\n",
    "from langchain_community.vectorstores import Neo4jVector\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.runnables import (\n",
    "    RunnableBranch,\n",
    "    RunnableLambda,\n",
    "    RunnableParallel,\n",
    "    RunnablePassthrough,\n",
    ")\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.vectorstores.neo4j_vector import remove_lucene_chars\n",
    "from typing import Tuple, List\n",
    "\n",
    "# Step 1: Set up the graph transformer\n",
    "def setup_graph_transformer(llm, documents, graph):\n",
    "    \"\"\"Set up the LLM-based graph transformer and add documents to the graph.\"\"\"\n",
    "    llm_transformer = LLMGraphTransformer(llm=llm)\n",
    "    graph_documents = llm_transformer.convert_to_graph_documents(documents)\n",
    "    graph.add_graph_documents(\n",
    "        graph_documents,\n",
    "        baseEntityLabel=True,\n",
    "        include_source=True\n",
    "    )\n",
    "\n",
    "# Step 2: Initialize Neo4j vector store\n",
    "def initialize_vector_store(embeddings):\n",
    "    \"\"\"Initialize a Neo4j vector store with specified embeddings.\"\"\"\n",
    "    return Neo4jVector.from_existing_graph(\n",
    "        embeddings,\n",
    "        search_type=\"hybrid\",\n",
    "        node_label=\"Document\",\n",
    "        text_node_properties=[\"text\"],\n",
    "        embedding_node_property=\"embedding\"\n",
    "    )\n",
    "\n",
    "# Step 3: Extract entities from text\n",
    "class Entities(BaseModel):\n",
    "    \"\"\"Identifying information about entities.\"\"\"\n",
    "    names: List[str] = Field(\n",
    "        ...,\n",
    "        description=\"All the person, organization, or business entities that appear in the text.\",\n",
    "    )\n",
    "\n",
    "def create_entity_extraction_prompt(llm):\n",
    "    \"\"\"Create a prompt for extracting entities.\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"You are extracting organization and person entities from the text.\",\n",
    "            ),\n",
    "            (\n",
    "                \"human\",\n",
    "                \"Use the given format to extract information from the following input: {question}\",\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    return prompt | llm.with_structured_output(Entities)\n",
    "\n",
    "# Step 4: Generate full-text query for graph search\n",
    "def generate_full_text_query(input: str) -> str:\n",
    "    \"\"\"Generate a full-text query for Neo4j.\"\"\"\n",
    "    full_text_query = \"\"\n",
    "    words = [el for el in remove_lucene_chars(input).split() if el]\n",
    "    for word in words[:-1]:\n",
    "        full_text_query += f\" {word}~2 AND\"\n",
    "    full_text_query += f\" {words[-1]}~2\"\n",
    "    return full_text_query.strip()\n",
    "\n",
    "# Step 5: Structured retrieval from Neo4j\n",
    "def structured_retriever(question: str, graph, entity_chain) -> str:\n",
    "    \"\"\"Retrieve structured data from Neo4j based on entities in the question.\"\"\"\n",
    "    result = \"\"\n",
    "    entities = entity_chain.invoke({\"question\": question})\n",
    "    for entity in entities.names:\n",
    "        response = graph.query(\n",
    "            \"\"\"CALL db.index.fulltext.queryNodes('entity', $query, {limit:2})\n",
    "            YIELD node,score\n",
    "            CALL {\n",
    "              WITH node\n",
    "              MATCH (node)-[r:!MENTIONS]->(neighbor)\n",
    "              RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\n",
    "              UNION ALL\n",
    "              WITH node\n",
    "              MATCH (node)<-[r:!MENTIONS]-(neighbor)\n",
    "              RETURN neighbor.id + ' - ' + type(r) + ' -> ' +  node.id AS output\n",
    "            }\n",
    "            RETURN output LIMIT 50\n",
    "            \"\"\",\n",
    "            {\"query\": generate_full_text_query(entity)},\n",
    "        )\n",
    "        result += \"\\n\".join([el['output'] for el in response])\n",
    "    return result\n",
    "\n",
    "# Step 6: Unified retriever combining structured and unstructured data\n",
    "def retriever(question: str, graph, vector_index, entity_chain):\n",
    "    \"\"\"Retrieve data from structured and unstructured sources.\"\"\"\n",
    "    print(f\"Search query: {question}\")\n",
    "    structured_data = structured_retriever(question, graph, entity_chain)\n",
    "    unstructured_data = [el.page_content for el in vector_index.similarity_search(question)]\n",
    "    final_data = f\"\"\"Structured data:\n",
    "    {structured_data}\n",
    "    Unstructured data:\n",
    "    {\"#Document \". join(unstructured_data)}\n",
    "    \"\"\"\n",
    "    return final_data\n",
    "\n",
    "# Step 7: Create a query condensing and answering pipeline\n",
    "def format_chat_history(chat_history: List[Tuple[str, str]]) -> List:\n",
    "    \"\"\"Format chat history into a list of messages.\"\"\"\n",
    "    buffer = []\n",
    "    for human, ai in chat_history:\n",
    "        buffer.append(HumanMessage(content=human))\n",
    "        buffer.append(AIMessage(content=ai))\n",
    "    return buffer\n",
    "\n",
    "def create_condense_question_prompt() -> PromptTemplate:\n",
    "    \"\"\"Create a prompt for condensing follow-up questions.\"\"\"\n",
    "    _template = \"\"\"Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question,\n",
    "in its original language.\n",
    "Chat History:\n",
    "{chat_history}\n",
    "Follow Up Input: {question}\n",
    "Standalone question:\"\"\"\n",
    "    return PromptTemplate.from_template(_template)\n",
    "\n",
    "def create_search_query_pipeline(llm, condense_prompt: PromptTemplate) -> RunnableBranch:\n",
    "    \"\"\"Create a pipeline to process search queries.\"\"\"\n",
    "    return RunnableBranch(\n",
    "        (\n",
    "            RunnableLambda(lambda x: bool(x.get(\"chat_history\"))).with_config(\n",
    "                run_name=\"HasChatHistoryCheck\"\n",
    "            ),\n",
    "            RunnablePassthrough.assign(\n",
    "                chat_history=lambda x: format_chat_history(x[\"chat_history\"])\n",
    "            )\n",
    "            | condense_prompt\n",
    "            | llm\n",
    "            | StrOutputParser(),\n",
    "        ),\n",
    "        RunnableLambda(lambda x: x[\"question\"]),\n",
    "    )\n",
    "\n",
    "def create_final_prompt_template() -> ChatPromptTemplate:\n",
    "    \"\"\"Create a final prompt template for answering questions.\"\"\"\n",
    "    template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Use natural language and be concise.\n",
    "Answer:\"\"\"\n",
    "    return ChatPromptTemplate.from_template(template)\n",
    "\n",
    "def create_query_pipeline(llm) -> RunnableParallel:\n",
    "    \"\"\"Create a pipeline for condensing questions and answering.\"\"\"\n",
    "    condense_prompt = create_condense_question_prompt()\n",
    "    search_query_pipeline = create_search_query_pipeline(llm, condense_prompt)\n",
    "    final_prompt = create_final_prompt_template()\n",
    "\n",
    "    return (\n",
    "        RunnableParallel(\n",
    "            {\n",
    "                \"context\": search_query_pipeline | retriever,\n",
    "                \"question\": RunnablePassthrough(),\n",
    "            }\n",
    "        )\n",
    "        | final_prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "question=input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(llm, documents, graph, embeddings, question):\n",
    "    \"\"\"Main function to run the retrieval pipeline.\"\"\"\n",
    "    setup_graph_transformer(llm, documents, graph)\n",
    "    vector_index = initialize_vector_store(embeddings)\n",
    "    entity_chain = create_entity_extraction_prompt(llm)\n",
    "    pipeline = create_query_pipeline(llm)\n",
    "    answer = pipeline.invoke({\"question\": question})\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[#CDBE]  _: <CONNECTION> error: Failed to read from defunct connection ResolvedIPv4Address(('34.126.161.242', 7687)) (ResolvedIPv4Address(('34.126.161.242', 7687))): OSError('No data')\n",
      "Unable to retrieve routing information\n",
      "Transaction failed and will be retried in 0.8825773787257747s (Unable to retrieve routing information)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "retriever() missing 3 required positional arguments: 'graph', 'vector_index', and 'entity_chain'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m answer\u001b[38;5;241m=\u001b[39mmain(llm,documents,graph,embeddings,question)\n",
      "Cell \u001b[1;32mIn[57], line 7\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(llm, documents, graph, embeddings, question)\u001b[0m\n\u001b[0;32m      5\u001b[0m entity_chain \u001b[38;5;241m=\u001b[39m create_entity_extraction_prompt(llm)\n\u001b[0;32m      6\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m create_query_pipeline(llm)\n\u001b[1;32m----> 7\u001b[0m answer \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39minvoke({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: question})\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m answer\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3022\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3020\u001b[0m context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[0;32m   3021\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 3022\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3023\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3024\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3727\u001b[0m, in \u001b[0;36mRunnableParallel.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3722\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[0;32m   3723\u001b[0m         futures \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   3724\u001b[0m             executor\u001b[38;5;241m.\u001b[39msubmit(_invoke_step, step, \u001b[38;5;28minput\u001b[39m, config, key)\n\u001b[0;32m   3725\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m key, step \u001b[38;5;129;01min\u001b[39;00m steps\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   3726\u001b[0m         ]\n\u001b[1;32m-> 3727\u001b[0m         output \u001b[38;5;241m=\u001b[39m {key: future\u001b[38;5;241m.\u001b[39mresult() \u001b[38;5;28;01mfor\u001b[39;00m key, future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(steps, futures)}\n\u001b[0;32m   3728\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   3729\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3727\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   3722\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[0;32m   3723\u001b[0m         futures \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   3724\u001b[0m             executor\u001b[38;5;241m.\u001b[39msubmit(_invoke_step, step, \u001b[38;5;28minput\u001b[39m, config, key)\n\u001b[0;32m   3725\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m key, step \u001b[38;5;129;01min\u001b[39;00m steps\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   3726\u001b[0m         ]\n\u001b[1;32m-> 3727\u001b[0m         output \u001b[38;5;241m=\u001b[39m {key: future\u001b[38;5;241m.\u001b[39mresult() \u001b[38;5;28;01mfor\u001b[39;00m key, future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(steps, futures)}\n\u001b[0;32m   3728\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   3729\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\concurrent\\futures\\_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3711\u001b[0m, in \u001b[0;36mRunnableParallel.invoke.<locals>._invoke_step\u001b[1;34m(step, input, config, key)\u001b[0m\n\u001b[0;32m   3709\u001b[0m context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[0;32m   3710\u001b[0m context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, child_config)\n\u001b[1;32m-> 3711\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m context\u001b[38;5;241m.\u001b[39mrun(\n\u001b[0;32m   3712\u001b[0m     step\u001b[38;5;241m.\u001b[39minvoke,\n\u001b[0;32m   3713\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   3714\u001b[0m     child_config,\n\u001b[0;32m   3715\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3024\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3022\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3023\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3024\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n\u001b[0;32m   3025\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   3026\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py:4713\u001b[0m, in \u001b[0;36mRunnableLambda.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   4699\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Invoke this Runnable synchronously.\u001b[39;00m\n\u001b[0;32m   4700\u001b[0m \n\u001b[0;32m   4701\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4710\u001b[0m \u001b[38;5;124;03m    TypeError: If the Runnable is a coroutine function.\u001b[39;00m\n\u001b[0;32m   4711\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4712\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunc\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 4713\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[0;32m   4714\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_invoke,\n\u001b[0;32m   4715\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   4716\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config(config, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc),\n\u001b[0;32m   4717\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4718\u001b[0m     )\n\u001b[0;32m   4719\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4720\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   4721\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot invoke a coroutine function synchronously.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4722\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse `ainvoke` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4723\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py:1927\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[1;34m(self, func, input, config, run_type, serialized, **kwargs)\u001b[0m\n\u001b[0;32m   1923\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[0;32m   1924\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, child_config)\n\u001b[0;32m   1925\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[0;32m   1926\u001b[0m         Output,\n\u001b[1;32m-> 1927\u001b[0m         context\u001b[38;5;241m.\u001b[39mrun(\n\u001b[0;32m   1928\u001b[0m             call_func_with_variable_args,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   1929\u001b[0m             func,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   1930\u001b[0m             \u001b[38;5;28minput\u001b[39m,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   1931\u001b[0m             config,\n\u001b[0;32m   1932\u001b[0m             run_manager,\n\u001b[0;32m   1933\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1934\u001b[0m         ),\n\u001b[0;32m   1935\u001b[0m     )\n\u001b[0;32m   1936\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1937\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\config.py:396\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[1;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[0;32m    395\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[1;32m--> 396\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py:4567\u001b[0m, in \u001b[0;36mRunnableLambda._invoke\u001b[1;34m(self, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[0;32m   4565\u001b[0m                 output \u001b[38;5;241m=\u001b[39m chunk\n\u001b[0;32m   4566\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4567\u001b[0m     output \u001b[38;5;241m=\u001b[39m call_func_with_variable_args(\n\u001b[0;32m   4568\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc, \u001b[38;5;28minput\u001b[39m, config, run_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m   4569\u001b[0m     )\n\u001b[0;32m   4570\u001b[0m \u001b[38;5;66;03m# If the output is a Runnable, invoke it\u001b[39;00m\n\u001b[0;32m   4571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, Runnable):\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\config.py:396\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[1;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[0;32m    395\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[1;32m--> 396\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mTypeError\u001b[0m: retriever() missing 3 required positional arguments: 'graph', 'vector_index', and 'entity_chain'"
     ]
    }
   ],
   "source": [
    "answer=main(llm,documents,graph,embeddings,question)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
